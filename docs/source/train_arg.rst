Mjlab Training Arguments
========================

Taken from ``manager_based_rl_env.py`` and ``config.py``

.. code-block:: bash

   uv run train Mjlab-Velocity-Flat-Unitree-G1 --help


1. Essential Setup
------------------

*These settings prevent crashes, manage disk space, and handle saving/resuming.*

+---------------------------+-------------+------------------------------------------------------------+
| Argument                  | Recommended | Description                                                |
+===========================+=============+============================================================+
| --env.scene.num-envs      | 1024        | Default (4096)                                             |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.resume            | True        | Resume training from a previous checkpoint.                |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.load-run          | "run_name"  | The specific run folder to resume from (e.g. "test_v1").  |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.run-name          | "test_v1"   | Names the run log (instead of random timestamp).           |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.max-iterations    | 5000        | Stops training automatically.                              |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.save-interval     | 100         | Saves disk space (default 50).                             |
+---------------------------+-------------+------------------------------------------------------------+
| --video                   | True        | Enable video recording.                                    |
+---------------------------+-------------+------------------------------------------------------------+


2. Organization & Logging
-------------------------

*Useful for keeping your experiments sorted.*

+---------------------------+-------------+------------------------------------------------------------+
| Argument                  | Default     | Description                                                |
+===========================+=============+============================================================+
| --agent.experiment-name   | "exp1"      | Group runs under a specific folder.                        |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.wandb-project     | "mjlab"     | Project name on WandB website.                             |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.logger            | "wandb"     | Logger type (wandb or tensorboard).                        |
+---------------------------+-------------+------------------------------------------------------------+
| --agent.load-checkpoint   | "model_.*.pt"| Regex to load specific checkpoint (e.g. model_1000.pt).   |
+---------------------------+-------------+------------------------------------------------------------+
| --video-length            | 200         | Length of recorded video in steps.                         |
+---------------------------+-------------+------------------------------------------------------------+
| --video-interval          | 2000        | How often (in steps) to record a video.                    |
+---------------------------+-------------+------------------------------------------------------------+
| --torchrunx-log-dir       | None        | Directory for torchrunx logs (multi-GPU only).             |
+---------------------------+-------------+------------------------------------------------------------+


3. Environment & Physics (--env.*)
----------------------------------

*Controls the simulation world.*

+-------------------------------+------------------+----------------------------------------------+
| Argument                      | Default          | Description                                  |
+===============================+==================+==============================================+
| --env.decimation              | Task Dependent   | Physics steps per control step.              |
+-------------------------------+------------------+----------------------------------------------+
| --env.episode-length-s        | 0.0              | Episode duration (seconds).                  |
+-------------------------------+------------------+----------------------------------------------+
| --env.is-finite-horizon       | False            | Hard reset at time limit.                    |
+-------------------------------+------------------+----------------------------------------------+
| --env.scale-rewards-by-dt     | True             | Scale rewards by timestep.                   |
+-------------------------------+------------------+----------------------------------------------+
| --env.seed                    | None             | Environment random seed.                     |
+-------------------------------+------------------+----------------------------------------------+
| --enable-nan-guard            | False            | Terminate if simulation errors (NaNs) occur. |
+-------------------------------+------------------+----------------------------------------------+


Simulation Sub-Settings (--env.sim.*)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+------------------------------------+----------+-------------------------------------------+
| Argument                           | Default  | Description                               |
+====================================+==========+===========================================+
| --env.sim.mujoco.timestep          | 0.005    | Physics timestep.                         |
+------------------------------------+----------+-------------------------------------------+
| --env.sim.mujoco.iterations        | 10       | Solver iterations (increase to 20).       |
+------------------------------------+----------+-------------------------------------------+
| --env.sim.mujoco.gravity           | 0 0 -9.81| Gravity vector.                           |
+------------------------------------+----------+-------------------------------------------+
| --env.sim.mujoco.solver            | newton   | Solver type.                              |
+------------------------------------+----------+-------------------------------------------+


Viewer Sub-Settings (--env.viewer.*)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------+------------+--------------------------+
| Argument                         | Default    | Description              |
+==================================+============+==========================+
| --env.viewer.lookat              | 0 0 0      | Camera target.           |
+----------------------------------+------------+--------------------------+
| --env.viewer.resolution          | (640,480)  | Window resolution.       |
+----------------------------------+------------+--------------------------+
| --env.viewer.enable-shadows      | True       | Enable shadows.          |
+----------------------------------+------------+--------------------------+


4. PPO Algorithm (Advanced Math)
--------------------------------

*Controls how the robot learns.*

+----------------------------------------+----------+----------------------------------+
| Argument                               | Default  | Description                      |
+========================================+==========+==================================+
| --agent.algorithm.learning-rate        | 1e-3     | Learning rate.                   |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.num-learning-epochs  | 5        | Epochs per update.               |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.num-mini-batches     | 4        | Mini-batches per epoch.          |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.gamma                | 0.99     | Discount factor.                 |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.lam                  | 0.95     | GAE lambda.                      |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.entropy-coef         | 0.005    | Entropy (exploration).           |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.desired-kl           | 0.01     | Target KL divergence.            |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.max-grad-norm        | 1.0      | Max gradient norm.               |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.value-loss-coef      | 1.0      | Value loss coefficient.          |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.clip-param           | 0.2      | PPO clip parameter.              |
+----------------------------------------+----------+----------------------------------+
| --agent.algorithm.schedule             | adaptive | LR schedule (adaptive/fixed).    |
+----------------------------------------+----------+----------------------------------+
